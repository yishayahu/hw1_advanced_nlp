{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Studets details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student1\n",
    "* Name:\n",
    "* ID:\n",
    "* Username:\n",
    "\n",
    "Student2\n",
    "* Name:\n",
    "* ID:\n",
    "* Username:\n",
    "\n",
    "Student3\n",
    "* Name:\n",
    "* ID:\n",
    "* Username:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General tip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While debugging you might want to use:\n",
    "```python\n",
    "import importlib\n",
    "importlib.reload(model)\n",
    "```\n",
    "\n",
    "to reload the model module without repeating unnecessary cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import relevant packages - you might need to pip install some "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import data_loader\n",
    "from traineval import train, evaluate\n",
    "import model as model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"deviced used is {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "\n",
    "The following line of code invokes data_loader and will automatically download and extract the dataset if needed.\n",
    "It instantiates the following variables;\n",
    "* tokens_vocab - the sentence words vocabulary\n",
    "* y_vocab - the labels (senses) vocabulary\n",
    "* datasets - a dictionary with train,dev, and test WSDDataset instances.\n",
    "\n",
    "Use the optional sentence_count kwarg to limit the number of sentences loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, tokens_vocab, y_vocab = data_loader.load_train_dataset()\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dataset = data_loader.load_dev_dataset(tokens_vocab, y_vocab)\n",
    "dev_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Query-Based Attention\n",
    "\n",
    "Implement the relevant parts in model.py module. You might to check out this blog post about [gather method](https://medium.com/analytics-vidhya/understanding-indexing-with-pytorch-gather-33717a84ebc4)\n",
    "\n",
    "Load the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = 0.25\n",
    "D = 300\n",
    "lr = 8e-5\n",
    "batch_size=100\n",
    "num_epochs=5\n",
    "set_seed(seed)\n",
    "\n",
    "m = model.WSDModel(\n",
    "    tokens_vocab.size(), \n",
    "    y_vocab.size(), \n",
    "    D=D, \n",
    "    dropout_prob=dropout\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(m.parameters(), lr=lr)\n",
    "\n",
    "losses, train_acc, val_acc = train(\n",
    "    m, optimizer, train_dataset, dev_dataset, num_epochs=num_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model - you shoud see the loss decreasing and validation acc increasing from epoch to epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Validation accuracy: {val_acc[-1]:.3f}, Training accuracy:{train_acc[-1]:.3f}\")\n",
    "assert round(val_acc[-1], 3) >= 0.514, \"The last validation accuracy should be at least 0.514. Please check your implementation before you continue\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the loss and training/validation accuracy. You should be getting ~54% validation accuracy after 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, figsize=(15, 6))\n",
    "\n",
    "axs[0].plot(losses, '-', label='Train Loss');\n",
    "axs[0].legend()\n",
    "axs[1].plot(train_acc, '-o', label='Train Acc');\n",
    "axs[1].plot(val_acc, '-o', label='Val Acc');\n",
    "axs[1].legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the attention vizualization to get a feel of what the model is attending to.\n",
    "\n",
    "The query token is highlighted in green, and the model's attention with a pink-blue gradient.\n",
    "In addition, the loss is given a red gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from traineval import higlight_samples\n",
    "\n",
    "higlight_samples(m, dev_dataset, sample_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Padding\n",
    "\n",
    "Implement the padding mask in the attention function in model.py.\n",
    "\n",
    "Load the model and retrain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(seed)\n",
    "\n",
    "m = model.WSDModel(\n",
    "    tokens_vocab.size(), \n",
    "    y_vocab.size(), \n",
    "    D=D, \n",
    "    dropout_prob=dropout,\n",
    "    use_padding=True\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(m.parameters(), lr=lr)\n",
    "\n",
    "losses, train_acc, val_acc = train(\n",
    "    m, optimizer, train_dataset, dev_dataset, num_epochs=num_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Validation accuracy: {val_acc[-1]:.3f}, Training accuracy:{train_acc[-1]:.3f}\")\n",
    "assert round(val_acc[-1], 3) >= 0.527, \"The last validation accuracy should be at least 0.527. Please check your implementation before you continue\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the loss and training/validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, figsize=(15, 6))\n",
    "\n",
    "axs[0].plot(losses, '-', label='Train Loss');\n",
    "axs[0].legend()\n",
    "axs[1].plot(train_acc, '-o', label='Train Acc');\n",
    "axs[1].plot(val_acc, '-o', label='Val Acc');\n",
    "axs[1].legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "higlight_samples(m, dev_dataset, sample_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine additional examples, using the API and pandas as demonstrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from traineval import evaluate_verbose, highlight\n",
    "\n",
    "pd.set_option('max_columns', 100)\n",
    "\n",
    "eval_df, attention_df = evaluate_verbose(m, dev_dataset, iter_lim=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of 5 incorrectly classified examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = np.where(eval_df['y_true'] != eval_df['y_pred'])\n",
    "idxs = list(idxs[0][:5])\n",
    "highlight(eval_df, attention_df, idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of examples with the query word \"left\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = np.where(eval_df['query_token'] == 'left')\n",
    "highlight(eval_df, attention_df, idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Self-Attention\n",
    "\n",
    "The method below converts the query-based instances in WSDDataset to sentence-level instances in WSDSentencesDataset for self-attention.\n",
    "\n",
    "Notice how the number of samples now equals number of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_train_dataset = data_loader.WSDSentencesDataset.from_word_dataset(train_dataset)\n",
    "sa_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_dev_dataset = data_loader.WSDSentencesDataset.from_word_dataset(dev_dataset)\n",
    "sa_dev_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement self-attention in the model.\n",
    "\n",
    "Load the model and retrain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=2e-4\n",
    "dropout = 0.2\n",
    "D=300\n",
    "batch_size=20\n",
    "num_epochs=5\n",
    "set_seed(seed)\n",
    "\n",
    "m = model.WSDModel(\n",
    "    tokens_vocab.size(), \n",
    "    y_vocab.size(), \n",
    "    D=D, \n",
    "    dropout_prob=dropout,\n",
    "    use_padding=True\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(m.parameters(), lr=lr)\n",
    "\n",
    "losses, train_acc, val_acc = train(\n",
    "    m, optimizer, sa_train_dataset, sa_dev_dataset, num_epochs=num_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the loss and training/validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Validation accuracy: {val_acc[-1]:.3f}, Training accuracy:{train_acc[-1]:.3f}\")\n",
    "assert val_acc[-1] >= 0.543, \"The last validation accuracy should be at least 0.543. Please check your implementation before you continue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, figsize=(15, 6))\n",
    "\n",
    "axs[0].plot(losses, '-', label='Train Loss');\n",
    "axs[0].legend()\n",
    "axs[1].plot(train_acc, '-o', label='Train Acc');\n",
    "axs[1].plot(val_acc, '-o', label='Val Acc');\n",
    "axs[1].legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Positional embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not provide \"you code here\" comments for this part as you should be familiar with the code by now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: your experiments here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Causal Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not provide \"you code here\" comments for this part as you should be familiar with the code by now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: your experiments here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}